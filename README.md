# 画像生成AI プロジェクト

このリポジトリは、Stable DiffusionとLoRAを用いて、独自の画像生成モデルを学習・実行するための一連のスクリプト群です。

---

##  各スクリプトの機能説明

### 1. 画像収集 (`scripts/crawl_images.py`)

Microsoftの検索エンジンBingを使って、指定したキーワードに合致する画像をインターネットから自動で収集し、指定したフォルダに保存するプログラムです。

**主な機能:**

* **キーワード検索**: 実行時に`--query`で指定したキーワード（例：「猫 かわいい イラスト」）で画像を検索します。
* **フィルタリング**: `--type`で画像の種類（写真、イラストなど）を、`--color`で色（カラー、モノクロ）を絞り込めます。
* **枚数指定**: `--max_num`でダウンロードしたい画像の最大枚数を指定できます。
* **保存先指定**: `--out_dir`で収集した画像の保存先フォルダを指定できます。

---

### 2. データ前処理

#### 2-1. 重複・類似画像の除去 (`scripts/dedup.py`)

画像データセットから重複、あるいは酷似している画像を自動で検出して除去するプログラムです。Webから画像を収集すると、同じ画像が複数枚ダウンロードされたり、解像度やファイル形式が違うだけのそっくりな画像が含まれたりすることがよくあります。このスクリプトは、そうした「無駄なデータ」を整理して、クリーンなデータセットを作成するのに役立ちます。

**処理の核となる技術:**

このプログラムの核となるのは、**Perceptual Hash（pHash）**という技術です。

1.  **画像の「見た目」を指紋化する**:
    ファイルサイズやファイル名が違っても、見た目が似ている画像を検出するために、まず各画像の「見た目の特徴（Perceptual Hash）」を計算します。これは、画像の内容を要約した一種の「指紋」のようなものです。
2.  **指紋同士の類似度を比較する**:
    次に、新しく読み込んだ画像の指紋（ハッシュ）を、既に「ユニークだ」と判断して保存済みの画像の指紋リストと比較します。この比較にはハミング距離という手法が使われ、2つの指紋がどれだけ違うか（=画像の見た目がどれだけ違うか）を数値で表します。
3.  **重複を判定して仕分ける**:
    ハミング距離が、あらかじめ設定した**しきい値（--threshold）**よりも小さい場合、それらの画像は「酷似している（重複）」と判断されます。重複と判断された画像はスキップされ、ユニークな画像のみが新しいフォルダにコピーされます。

---

#### 2-2. 画像のリサイズとセンタリング (`scripts/resize_and_center.py`)

AIモデルの学習用に画像データを前処理するためのプログラムです。さまざまなサイズやアスペクト比の画像を、元の画像の比率を保ったまま、指定された正方形のサイズに統一します。

AIの学習、特にStable Diffusionのようなモデルでは、入力画像を同じサイズ（例: 512x512ピクセル）に揃える必要があります。このコードは、画像の構図が崩れるのを防ぐために以下の手順を踏みます。

1.  **画像の縮小**: 元画像の縦横比を維持したまま、指定した正方形のサイズ（例: 512x512）の枠内に収まるように画像を縮小します。
2.  **背景（キャンバス）の作成**: 目標サイズの真っ白な正方形の背景（キャンバス）を用意します。
3.  **画像の貼り付け**: 縮小した画像を、用意した白いキャンバスの中央に貼り付けます。これにより、元画像が横長だった場合は上下に、縦長だった場合は左右に余白ができます。
4.  **保存**: 最終的に出来上がった「余白付きの正方形画像」をJPEG形式で保存します。

この処理により、全ての画像が歪みなく、同じサイズの正方形データとして揃うため、AIの学習データとして最適な状態になります。

---

#### 2-3. 自動キャプション生成 (`scripts/caption_blip.py`)

指定された画像に対して、AIモデル（BLIPなど）を用いて説明文（キャプション）を自動で生成し、テキストファイルとして保存するプログラムです。

**主な処理の流れ:**

1.  **準備と設定の読み込み**:
    `argparse`ライブラリを使い、ユーザーがコマンドラインから指定した設定（画像フォルダ、キャプション保存先、使用モデル、バッチサイズなど）を読み込みます。
2.  **AIモデルのロード**:
    Hugging Faceの`transformers`ライブラリが提供する`pipeline`機能を使って、画像からテキストを生成するためのAIモデル（"image-to-text"）を読み込み、使える状態にします。
3.  **画像処理とキャプション生成**:
    指定された画像フォルダから画像ファイルをリストアップし、進捗状況バーを表示しながら、バッチサイズごとに以下の処理を繰り返します。
    * **画像の読み込み**: バッチ分の画像ファイルを読み込み、AIモデルが処理できる形式（RGB）に変換します。
    * **推論の実行**: 準備したAIモデルに画像のバッチを渡し、それぞれの画像に対応するキャプションを生成させます。
    * **結果の保存**: 生成されたキャプションを、元の画像ファイルと同じ名前のテキストファイル（例: `inu_01.jpg` → `inu_01.txt`）として、指定された保存用フォルダに書き出します。

---

### 3. LoRAモデルの学習 (`scripts/train_lora.py`)

Stable DiffusionのLoRA（Low-Rank Adaptation）を追加学習させるためのプログラムです。特定のキャラクターや画風などを学習させ、それを再現するための小さな「差分ファイル」を作成します。

このコードは、Stable Diffusionの巨大なモデル全体を再学習するのではなく、一部の層に「LoRA」と呼ばれる小さな追加モジュールを挿入し、その小さなモジュールだけを集中して学習させます。

**主な処理の流れ:**

1.  **モデルとデータの準備** :
    土台となるStable Diffusionの基本モデル（UNet, VAE, Text Encoder）を読み込みます。学習させたい**画像と、その説明文（キャプション）**のペアからなるデータセットを用意します。
2.  **LoRAの注入とパラメータの凍結** :
    画像生成の核となるUNetモデルの各層に、`peft`ライブラリを使って学習可能なLoRAモジュールを挿入します。LoRA以外の、元からある巨大なモデルのパラメータは**すべて「凍結」**し、学習中に一切変更されないようにします。これにより、計算コストを大幅に削減できます。
3.  **学習ループ** :
    データセットから画像とキャプションを取り出し、画像にノイズを加えます。UNetに「このキャプションをヒントに、画像からノイズを予測（除去）して」と指示し、その予測と実際のノイズとの**誤差（loss）**を計算します。その誤差が小さくなるように、LoRAモジュールのパラメータだけを微調整するプロセスを何千ステップも繰り返します。
4.  **LoRAファイルの保存** :
    学習が完了したら、変更が加えられたLoRAモジュールの重みだけを抽出し、一つのファイル（`.safetensors`など）として保存します。

---

### 4. 画像生成（推論） (`scripts/inference.py`)

学習済みのLoRAという追加学習データを使って、特定のキャラクターや画風を再現する画像を生成するプログラムです。Stable Diffusionの基本的なモデルに、LoRAの「差分ファイル」を読み込ませて、カスタマイズされた画像を生成します。

**処理の概要:**

1.  **モデルの準備**:
    まず、土台となるStable Diffusionの標準モデル（例: `stable-diffusion-v1-5`）をGPUに読み込みます。次に、ユーザーが指定したLoRAの重みファイル（特定の画風やキャラクターを学習させた追加データ）を読み込み、標準モデルと結合させます。`fuse_lora()`という処理で、この結合を事前に行うことで生成速度を上げています。
2.  **省メモリ設定**:
    `enable_vae_slicing()`や`enable_attention_slicing()`といった最適化機能を有効にしています。これは、VRAM（ビデオメモリ）が少ないGPUでも高解像度の画像を生成できるように、計算を小分けにしてメモリ消費を抑えるための設定です。
3.  **画像の生成と保存**:
    ユーザーが指定したプロンプト（「青い目の女の子」など）や、ネガティブプロンプト（「低品質」など）、その他のパラメータ（ステップ数や忠実度）を元に画像を生成します。完成した画像を、指定されたファイル名で保存します。

簡単に言うと、「汎用的なAI（ベースモデル）」に「特定の画風を教える追加データ（LoRA）」を適用し、ユーザーの指示（プロンプト）に従って一枚の絵を完成させる、という流れのプログラムです！